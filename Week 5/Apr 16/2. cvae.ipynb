{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "MTKwbguKwT4R"
   },
   "source": [
    "# CS492 전산학특강<인공지능 산업 및 스마트에너지>\n",
    "## Deep Learning Practice \n",
    "#### Prof. Ho-Jin Choi\n",
    "#### School of Computing, KAIST\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xfNT-mlFwxVM"
   },
   "source": [
    "## Week 5 - Advanced Models (1)\n",
    "### 1. Image Captioning with Visual Attention  \n",
    "### 2. Convolutional Variational Autoencoder \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITZuApL56Mny"
   },
   "source": [
    "## 2. Convolutional Variational Autoencoder \n",
    "\n",
    "### What is the Variational Autoencoder(VAE)?\n",
    "(refer: https://datascienceschool.net/view-notebook/c5248de280a64ae2a96c1d4e690fdf79/)\n",
    "\n",
    "<img src=\"https://datascienceschool.net/upfiles/f38b90fa89cb46eba22178edbae07a26.png\" width=\"700\">\n",
    "\n",
    "VAE는 Generative Model 중 하나로, 확률분포($P(x)$)를 학습함으로써, 데이터를 생성하는 것이 목적이다.\n",
    "Encoder 네트워크는 학습용 데이터(이하 $x$)를 입력으로 받고 잠재 변수(이하  $z$)의 확률분포에 대한 파라미터를 출력한다. 그리고 Decoder는 잠재변수에 대한 확률 분포 $p(z)$ 에서 샘플링한 벡터를 입력받아, 이를 이용해 원본 이미지를 복원한다.\n",
    "\n",
    "VAE는 최적화를 통해 아래의 두가지 문제를 푼다.\n",
    "1. 주어진 데이터를 잘 설명하는 잠재 변수의 분포를 찾는 것 (Encoder 역할) -> $q_{\\phi}(z|x)$\n",
    "1. 잠재변수로 부터 원본 이미지와 같은 이미지를 복원 (Decoder 역할) -> $p_{\\theta}(x|z)$\n",
    "\n",
    "**MNIST 생성 예:**\n",
    "\n",
    "![evolution of output during training](https://tensorflow.org/images/autoencoders/cvae.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder \n",
    "Encoder의 역할은 데이터가 주어졌을 때 Decoder가 원래의 데이터로 잘 복원할 수 있는 $z$ 를 샘플링 할 수 있는 이상적인 확률분포 $p(z|x)$ 를 찾는 것이다. 하지만 어떤 것이 이상적인 확률분포 $p(z|x)$ 인지는 아무도 모른다. VAE 방법론에서는 이 문제를 해결하기 위해 **Variational Inference(VI)**를 사용한다. (VI의 자세한 설명은 https://blog.evjang.com/2016/08/variational-bayes.html 참조)\n",
    "\n",
    "우리가 찾고 싶은 분포 $p(z|x)$는 Bayes' rule에 의해 다음과 같이 표현 가능\n",
    "$p(z|x) = \\frac{p(x|z)p(z)}{p(x)}$. 여기서 분모 $p(x)$는 $\\int_{z}p(x|z)p(z) dz$ 로써, intractable한 계산량을 가지고 있다. 즉, posterior에 해당하는 $p(z|x)$를 estimate 해야하며 이에 대한 대표적인 방법론으로 sampling 기반의 Markov chain Monte Carlo(MCMC)와 VI 방법론이 있다. \n",
    "\n",
    "MCMC 방법론의 경우, 추정하려는 분포의 parameter 수가 많으면 매우 느려지기 때문에 VAE에서는 보통 VI를 사용하여 posterior를 추정한다. \n",
    "\n",
    "##### Variational Inference\n",
    "우리가 이상적인 확률분포를 모르지만, 이를 추정하기 위해서 다루기 쉬운 분포(approximation class, 대표적으로 Gaussian distribution)를 가정하고 이 확률분포의 모수(평균, 분산)를 바꿔가며, 이상적인 확률분포에 근사하게 만들어 그 확률분포를 대신 사용하는 것이다. 이 다루기 쉬운 분포를 $q_{\\phi}$ 라고 한다면, Encoder는 $\\phi$ 라는 파라미터들을 바꾸어가며, $q_{\\phi}(z|x)$  확률 분포를 이상적인 확률 분포 $p(z|x)$ 에 근사시키는 역할을 수행한다. 보통 $q_{\\phi}(\\cdot)$ 은 Gaussian 정규 분포라고 가정하며, $z$ 의 marginal distribution은 평균이 0이고 분산이 1인 표준 정규분포로 가정한다.\n",
    "\n",
    "<img src=\"https://datascienceschool.net/upfiles/da522e75af6544c1a4ae09be69ed1a48.png\" width=\"700\">\n",
    "\n",
    "VI는 우리가 목표로 하는 이상적인 확률분포 $P$를 근사하는 확률분포 $Q$를 추정하기 위해 Kullback–Leibler divergence(KLD)를 이용하여 두 분포 사이의 차이를 계산하고, 이를 minimizing 하게된다. 즉, 우리가 구해야 하는 KLD에 대한 식은 다음과 같다.\n",
    "\n",
    "$KL(Q_\\phi(Z|X)||P(Z|X)) = \\sum_{z \\in Z}{q_\\phi(z|x)\\log\\frac{q_\\phi(z|x)}{p(z|x)}}$\n",
    "\n",
    "위 식은 reverse KLD로써, 분포 $P(Z)$와 분포 $Q_{\\phi}(Z)$ 사이의 정보량의 차이를 계산하고, 이 차이를 분포 $Q$의 파라미터 $\\phi$에 대해 minimizing함으로써 분포 $P$를 추정한다.\n",
    "\n",
    "$\\phi^*=arg\\min_\\phi KL(Q(Z|X)||p(Z|X))$\n",
    "\n",
    "<img src=\"https://3.bp.blogspot.com/-fHQrw49f-GI/V6ghG9Lv2YI/AAAAAAAAFFw/KUHaZF9Xu-8W4nIUJQZp0T_4nbY63Tz0gCLcB/s640/reverse-KL.png\" width=\"700\">\n",
    "\n",
    "\n",
    "#### Decoder\n",
    "Decoder는 추출한 샘플을 입력으로 받아 다시 원본으로 재구축하는 역할을 수행한다. 즉, decoder 파마리터 $\\theta$에 대해 $p_{\\theta}(x|z)$로부터 원본을 복원한다. \n",
    "\n",
    "정리하면, VAE의 encoder는 우리가 가지고 있는 데이터($x$)의 분포를 z를 통해 잘 표현할 수 있는 $q_{\\phi}(p(z|x)$ 분포와 $q_{\\phi}$ 분포로부터 셈플링된 잠재변수 $z$를 이용하여 원래 데이터 생성을 위한 $p_{\\theta}$ 분포를 학습하여, 테스트 단계에서 새로운 이미지에 대해서 그대로 입력 이미지를 복원시킨다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "## Import TensorFlow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import imageio\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "## Load the MNIST dataset\n",
    "Each MNIST image is originally a vector of 784 integers, each of which is between 0-255 and represents the intensity of a pixel. We model each pixel with a Bernoulli distribution in our model, and we statically binarize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4fYMGxGhrna"
   },
   "outputs": [],
   "source": [
    "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFC2ghIdiZYE"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "# Normalizing the images to the range of [0., 1.]\n",
    "train_images /= 255.\n",
    "test_images /= 255.\n",
    "\n",
    "# Binarization\n",
    "train_images[train_images >= .5] = 1.\n",
    "train_images[train_images < .5] = 0.\n",
    "test_images[test_images >= .5] = 1.\n",
    "test_images[test_images < .5] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4PIDhoDLbsZ"
   },
   "outputs": [],
   "source": [
    "TRAIN_BUF = 60000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "TEST_BUF = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIGN6ouoQxt3"
   },
   "source": [
    "## Use *tf.data* to create batches and shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yKCCQOoJ7cn"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(TRAIN_BUF).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images).shuffle(TEST_BUF).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_enc = tf.keras.layers.InputLayer(input_shape=(28, 28, 1))\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu')\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.dense_mean = tf.keras.layers.Dense(latent_dim)\n",
    "        self.dense_log_var = tf.keras.layers.Dense(latent_dim)\n",
    "               \n",
    "    def call(self, inputs):\n",
    "        x = self.input_enc(inputs)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flat(x)\n",
    "        mean = self.dense_mean(x)\n",
    "        log_var = self.dense_log_var(x)\n",
    "        \n",
    "        return mean, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_dec = tf.keras.layers.InputLayer(input_shape=(latent_dim,))\n",
    "        self.dense = tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu)\n",
    "        self.reshape = tf.keras.layers.Reshape(target_shape=(7, 7, 32))\n",
    "        self.conv_trans1 = tf.keras.layers.Conv2DTranspose(filters=64,\n",
    "                                                           kernel_size=3,\n",
    "                                                           strides=(2, 2),\n",
    "                                                           padding=\"SAME\",\n",
    "                                                           activation='relu')\n",
    "        self.conv_trans2 = tf.keras.layers.Conv2DTranspose(filters=32,\n",
    "                                                           kernel_size=3,\n",
    "                                                           strides=(2, 2),\n",
    "                                                           padding=\"SAME\",\n",
    "                                                           activation='relu')\n",
    "        # No activation\n",
    "        self.conv_trans3 =  tf.keras.layers.Conv2DTranspose(filters=1, \n",
    "                                                            kernel_size=3, \n",
    "                                                            strides=(1, 1), \n",
    "                                                            padding=\"SAME\")\n",
    "\n",
    "    def call(self, inputs, apply_sigmoid):\n",
    "        x = self.input_dec(inputs)\n",
    "        x = self.dense(x)\n",
    "        x = self.reshape(x)\n",
    "        x = self.conv_trans1(x)\n",
    "        x = self.conv_trans2(x)\n",
    "        x = self.conv_trans3(x)\n",
    "        \n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(x)\n",
    "            return probs\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELBO (Evidence Lower Bound)\n",
    "\n",
    "Encoder에서 이상적인 분포 $P(Z|X)$에 대해 근사하는 $Q_{\\phi}(Z|X)$를 구하기 위해 KLD를 사용했었는데, 이에 대한 수식을 다시 정리하면,\n",
    "\n",
    "\\begin{align} \n",
    "KL(Q||P) & = \\sum_{z \\in Z}{q_\\phi(z|x)\\log\\frac{q_\\phi(z|x)p(x)}{p(z,x)}} && \\text{(1)} \\\\ \n",
    "& = \\sum_{z \\in Z}{q_\\phi(z|x)\\big(\\log{\\frac{q_\\phi(z|x)}{p(z,x)}} + \\log{p(x)}\\big)} \\\\ \n",
    "& = \\Big(\\sum_{z}{q_\\phi(z|x)\\log{\\frac{q_\\phi(z|x)}{p(z,x)}}}\\Big) + \\Big(\\sum_{z}{\\log{p(x)}q_\\phi(z|x)}\\Big) \\\\ \n",
    "& = \\Big(\\sum_{z}{q_\\phi(z|x)\\log{\\frac{q_\\phi(z|x)}{p(z,x)}}}\\Big) + \\Big(\\log{p(x)}\\sum_{z}{q_\\phi(z|x)}\\Big) && \\text{note: $\\sum_{z}{q(z)} = 1 $} \\\\ \n",
    "& = \\log{p(x)} + \\Big(\\sum_{z}{q_\\phi(z|x)\\log{\\frac{q_\\phi(z|x)}{p(z,x)}}}\\Big)  \\\\ \n",
    "\\end{align}\n",
    "\n",
    "와 같이 정리된다. 여기서 $log p(x)$는 우리가 학습하려는 $\\phi$와 관련없으므로 상수로 치면, 결국 KLD는 $\\Big(\\sum_{z}{q_\\phi(z|x)\\log{\\frac{q_\\phi(z|x)}{p(z,x)}}}\\Big)$를 최소화하는 것과 같게 된다. 이를 다시 풀어쓰면 다음과 같다.\n",
    "\n",
    "\\begin{align} \n",
    "\\sum_{z}{q_\\phi(z|x)\\log{\\frac{q_\\phi(z|x)}{p(z,x)}}} & = \\mathbb{E}_{z \\sim Q_\\phi(Z|X)}\\big[\\log{\\frac{q_\\phi(z|x)}{p(z,x)}}\\big]\\\\ \n",
    "& = \\mathbb{E}_Q\\big[ \\log{q_\\phi(z|x)} - \\log{p(x,z)} \\big] \\\\ \n",
    "& = \\mathbb{E}_Q\\big[ \\log{q_\\phi(z|x)} - (\\log{p(x|z)} + \\log(p(z))) \\big] && \\text{(via  $\\log{p(x,z)=p(x|z)p(z)}$) }\\\\ \n",
    "& = \\mathbb{E}_Q\\big[ \\log{q_\\phi(z|x)} - \\log{p(x|z)} - \\log(p(z))) \\big] \\\\ \n",
    "\\end{align} \n",
    "\n",
    "즉, 위의 식을 최소화하는 것은, 전체식에 -1을 곱한 식을 최대화 하는것과 같으므로,\n",
    "\n",
    "\\begin{align} \n",
    "\\text{maximize } \\mathcal{L} & = -\\sum_{z}{q_\\phi(z|x)\\log{\\frac{q_\\phi(z|x)}{p(z,x)}}} \\\\ \n",
    "& = \\mathbb{E}_Q\\big[ -\\log{q_\\phi(z|x)} + \\log{p(x|z)} + \\log(p(z))) \\big] \\\\ \n",
    "& =  \\mathbb{E}_Q\\big[ \\log{p(x|z)} + \\log{\\frac{p(z)}{ q_\\phi(z|x)}} \\big] && \\text{(2)} \\\\ \n",
    "\\end{align}\n",
    "\n",
    "와 같이 표현 가능하며, $\\mathcal{L}$을 다시 정리하면,\n",
    "\n",
    "\\begin{align*} \n",
    "\\mathcal{L} & =  \\mathbb{E}_Q\\big[ \\log{p(x|z)} + \\log{\\frac{p(z)}{ q_\\phi(z|x)}} \\big] \\\\ \n",
    "& =   \\mathbb{E}_Q\\big[ \\log{p(x|z)} \\big] + \\sum_{Q}{q(z|x)\\log{\\frac{p(z)}{ q_\\phi(z|x)}}} && \\text{Definition of expectation} \\\\ \n",
    "& =  \\mathbb{E}_Q\\big[ \\log{p(x|z)} \\big] - KL(Q(Z|X)||P(Z)) && \\text{Definition of KL divergence} && \\text{(3)} \n",
    "\\end{align*}\n",
    "\n",
    "과 같이 된다. 원래 목적인 $KL(Q||P)$ 식을 $log p(x)$에 대해 다시 정리하면 다음과 같다. \n",
    "\n",
    "\\begin{align*} \n",
    "KL(Q||P) & = \\log p(x) - \\mathcal{L} \\\\ \n",
    "\\log p(x) & = \\mathcal{L} + KL(Q||P) && \\text{(4)} \n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "\\log p(x) \\ge ELBO\n",
    "\\end{align*}\n",
    "\n",
    "초기 우리가 구하고자 헀던 $P(Z|X)$는 분모인 $P(X)$가 계산가능하지 않기 때문에 VI를 이용하여 posterior를 추정하였다. 위 식에따라 $P(X)$는 $\\mathcal{L}$와 KLD 값으로 계산가능하며, KLD 식은 Jensen's Inequality에 의하여 항상 0보다 큰 값을 가지므로 결국 $log p(x)$ 값은 $\\mathcal{L}$ 값보다 항상 크거나 같게된다. 우리는 이러한 $\\mathcal{L}$을 **ELVO(Evidence Lower Bound)**라 부르며 결론적으로 $\\mathcal{L}$을 최대화하도록 $\\phi$를 학습하면된다.\n",
    "\n",
    "<img src=\"https://datascienceschool.net/upfiles/2b17600871204ad69d074389bab587c4.png\" width=\"600\">\n",
    "\n",
    "\n",
    "따라서, 결론적으로 $\\mathcal{L}$ 내부의 값들만 계산하면 되는데, $\\mathcal{L}$ 식을 다시확인하면,\n",
    "\n",
    "$\\mathcal{L} = \\log p(x) - KL(Q(Z|X)||P(Z|X)) = \\mathbb{E}_Q\\big[ \\log{p(x|z)} \\big] - KL(Q(Z|X)||P(Z))$\n",
    "\n",
    "와 같으며, 식은 크게 $Q$분포로 부터 **smapling**된 $log p(x|z)$에 대한 기댓값과 $Q(Z|X)$와 $P(Z)$에 대한 KLD 값으로 계산된다.\n",
    "\n",
    "### Reparameterization Trick\n",
    "Encoder가 출력하는 것은 $q_{\\phi}q(z|x)$ 확률 분포의 모수이다. 우리는 $q_{\\phi}q(z|x)$ 를 정규 분포라고 가정했기 때문에, 이 경우에는 평균과 분산이다. 다음 단계는 이 확률분포로 부터 샘플링을 하는 것이다. 이 때, 그냥 샘플링을 한다면 Back propagation이 불가능하다. Back propagation은 편미분을 구함으로써 Gradient를 구하는 것인데, $z$ 를 확률분포에서 그냥 샘플링 한다면 체인룰이 중간에 끊기게 된다. 이를 극복하기 위해서 Reparameterization trick을 사용했다.\n",
    "\n",
    "$\\mathcal{L}$에 대한 식을 다시보면, 이 식을 계산하기 위해 encoder로부터 나온 평균, 분산으로 만들어지는 확률분포에서 우리는 $z$값을 샘플링 하게된다. 이렇게 샘플리 되는 값들은 모델 자체에 stochasticity 한 속성을 부여하기 때문에, 동일한 입력에 대해서 같은 출력이 나오는 determinative한 deep learning 모델에 적용할 수 없다. (=> 즉, gradient descent 적용 X)\n",
    "\n",
    "이를 해결하기 위해, 임의의 정규분포를 갖는 노이즈 변수 $\\epsilon$으로부터 어떤 값을 샘플링하고, 이를 $Q$ 분포의 평균과 분산을 이용하여 미분가능한 변환함수로 만들어서, $z$값을 계산하게된다.  \n",
    "<img src=\"https://1.bp.blogspot.com/-fOv-fxk6W0Y/WQ13qrHrulI/AAAAAAAABqw/dTXlXdQHIrAGjjz5Vm7X97RkxvV4-FZuwCK4B/s1600/vae_4.PNG\" width=\"600\">\n",
    "\n",
    "$\\tilde{z}=g_\\phi (\\epsilon,x)~~with~~\\epsilon\\sim p(\\epsilon).$ \n",
    "$g_\\phi (\\epsilon,x)$는 $\\phi$로 미분가능한 변환 함수이며, 이 함수를 이용하여 임의의 함수 $f(z)$의 $Q_{\\phi}(z|x)$에 대한 Monte Carlo expectation estimate를 이용해 기댓값 식을 다음과 같이 바꿀 수 있다. \n",
    "\n",
    "$\\mathbb{E}_{q_\\phi(z|x^{(i)})}\\left[f(z)\\right]=\\mathbb{E}_{p(\\epsilon)}\\left[f(g_\\phi (\\epsilon,x^{(i)}))\\right]=\\frac{1}{L}\\sum_{l=1}^L f(g_\\phi (\\epsilon^{(l)},x^{(i)})),~~where~~\\epsilon^{(l)}\\sim p(\\epsilon).$\n",
    "\n",
    "single value estimage에 대한 식은 다음과 같다. \n",
    "\n",
    "$\\tilde{\\cal{L}}(\\theta,\\phi;x^{(i)})=-D_{KL}(q_\\phi(z|x^{(i)})||p_\\theta(z))+\\frac{1}{L}\\sum_{l=1}^L (\\log p_\\theta(x^{(i)}|z^{(i,l)})), \\\\where~~z^{(i,l)}=g_\\phi (\\epsilon^{(i,l)},x^{(i)})~~and~~\\epsilon^{(l)}\\sim p(\\epsilon).$\n",
    "\n",
    "결론적으로 stochasticity한 성질은 $\\epsilon$에 의해 확률적 특성이 보존되고, 변환함수가 $\\phi$에 대해 미분가능하므로, 학습과정에서 gradient descent를 이용하여 역전파가 가능해진다. 보통 가우시안 분포에 대해 변환함수는 다음과 같다. \n",
    "\n",
    "$z=\\mu(X)+\\Sigma^{1/2}*\\epsilon$\n",
    "\n",
    "\n",
    "<img src=\"https://1.bp.blogspot.com/-V-m6dOVaUL8/WQ2JKJ4Jj4I/AAAAAAAABrA/BjxqKMDfR6ggYCCqUNlBFiS4cqlyisgKACK4B/s1600/vae_3.PNG\" width=\"500\">\n",
    "\n",
    "$\\mathcal{L}$의 실제값의 계산은, 기댓값은 위의 변환함수로부터 샘플링된 $z$를 이용하여 샘플의 표본평균으로 계산가능하며, KLD의 경우, $Q_{\\phi}(z|x^i)$와 $P(z)$ 두 multivariate Gaussian 분포에 대한 KLD 식으로 계산 가능하다. (자세한 식 참고: https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Multivariate_normal_distributions)\n",
    "\n",
    "본 실습에서는 $\\mathbb{E}_{q_\\phi(z|x)}[\\log(p(x|z))] + \\mathbb{E}_{q_\\phi(z|x)}[\\log(p(z))] - \\mathbb{E}_{q_\\phi(z|x)}[\\log(q(z|x))]$의 값을 이용하여 학습에 이용할 것이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    def __init__(self, latent_dim=32, name='autoencoder', **kwargs):\n",
    "        super(CVAE, self).__init__(name=name, **kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = Encoder(latent_dim=latent_dim)\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "    def call(self, x):\n",
    "        mean, log_var = \n",
    "        z = \n",
    "        reconstructed = \n",
    "        \n",
    "        # Add KL divergence regularization loss.\n",
    "        #kl_loss = - 0.5 * tf.reduce_mean(\n",
    "        #    log_var - tf.square(mean) - tf.exp(log_var) + 1)\n",
    "        # self.add_loss(kl_loss)\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "    \n",
    "    def compute_loss(reconstructed, x):\n",
    "        cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=reconstructed, labels=x)\n",
    "        \n",
    "        logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "        logpz = self.log_normal_pdf(z, 0., 0.)\n",
    "        logqz_x = self.log_normal_pdf(z, mean, logvar)\n",
    "        \n",
    "        return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "    \n",
    "    def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "        log2pi = tf.math.log(2. * np.pi)\n",
    "        return tf.reduce_sum(\n",
    "            -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "            axis=raxis)\n",
    "    \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decoder(eps, apply_sigmoid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "* We start by iterating over the dataset\n",
    "* During each iteration, we pass the image to the encoder to obtain a set of mean and log-variance parameters of the approximate posterior $q(z|x)$\n",
    "* We then apply the *reparameterization trick* to sample from $q(z|x)$\n",
    "* Finally, we pass the reparameterized samples to the decoder to obtain the logits of the generative distribution $p(x|z)$\n",
    "* **Note:** Since we use the dataset loaded by keras with 60k datapoints in the training set and 10k datapoints in the test set, our resulting ELBO on the test set is slightly higher than reported results in the literature which uses dynamic binarization of Larochelle's MNIST.\n",
    "\n",
    "### Generate Images\n",
    "\n",
    "* After training, it is time to generate some images\n",
    "* We start by sampling a set of latent vectors from the unit Gaussian prior distribution $p(z)$\n",
    "* The generator will then convert the latent sample $z$ to logits of the observation, giving a distribution $p(x|z)$\n",
    "* Here we plot the probabilities of Bernoulli distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model.sample(test_input)\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "    # tight_layout minimizes the overlap between 2 sub-plots\n",
    "    plt.savefig(os.path.join('./cvae_results', 'image_at_epoch_{:04d}.png'.format(epoch)))\n",
    "    plt.show()\n",
    "    \n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "        axis=raxis)\n",
    "\n",
    "@tf.function\n",
    "def compute_loss(x, mean, log_var, z, reconstructed):\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=reconstructed, labels=x)\n",
    "    \n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, log_var)\n",
    "    \n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "latent_dim = 50\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "\n",
    "model = CVAE(latent_dim)\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "generate_and_save_images(model, 0, random_vector_for_generation)\n",
    "\n",
    "# Iterate over epochs.\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for x_batch_train  in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            mean, log_var, z, reconstructed = \n",
    "            loss = \n",
    "            \n",
    "        gradients = \n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "    end_time = time.time()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        loss = tf.keras.metrics.Mean()\n",
    "        for x_batch_test in test_dataset:\n",
    "            mean, log_var, z, reconstructed = model(x_batch_test)\n",
    "            loss(compute_loss(x_batch_test, mean, log_var, z, reconstructed))\n",
    "            \n",
    "        elbo = -loss.result()\n",
    "        display.clear_output(wait=False)\n",
    "        print('Epoch: {}, Test set ELBO: {}, '\n",
    "              'time elapse for current epoch {}'.format(epoch,\n",
    "                                                        elbo,\n",
    "                                                        end_time - start_time))\n",
    "        \n",
    "        generate_and_save_images(model, epoch, random_vector_for_generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4M_vIbUi7c0"
   },
   "source": [
    "### Display an image using the epoch number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WfO5wCdclHGL"
   },
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "    return PIL.Image.open(os.path.join('./cvae_results', 'image_at_epoch_{:04d}.png'.format(epoch_no)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5x3q9_Oe5q0A"
   },
   "outputs": [],
   "source": [
    "plt.imshow(display_image(epochs))\n",
    "plt.axis('off')# Display images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NywiH3nL8guF"
   },
   "source": [
    "### Generate a GIF of all the saved images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IGKQgENQ8lEI"
   },
   "outputs": [],
   "source": [
    "anim_file = 'cvae.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('./cvae_results/image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        frame = 2*(i**0.5)\n",
    "        if round(frame) > round(last):\n",
    "            last = frame\n",
    "        else:\n",
    "            continue\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "\n",
    "import IPython\n",
    "if IPython.version_info >= (6,2,0,''):\n",
    "    display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQXO_dlXkKsT"
   },
   "source": [
    "If you're working in Colab you can download the animation with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fSJS3m5HLFM"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "except ImportError:\n",
    "    pass\n",
    "else:\n",
    "    files.download(anim_file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cvae.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
