{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEP532 인공지능 이론과 실제\n",
    "## Deep Learning Practice \n",
    "#### Prof. Ho-Jin Choi\n",
    "#### School of Computing, KAIST\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Basic of Tensorflow**  \n",
    "    1-1. Introduction to Tensorflow  \n",
    "    1-2. Tensors and operations based on eager execution  \n",
    "    1-3. Neural networks in TensorFlow \n",
    "    \n",
    "1. **MLP-based Classification**   \n",
    "    2-1. Image classification  \n",
    "    2-2. Text classification  \n",
    "    2-3. Overfitting and how to fight it  \n",
    "    2-4. Save and restore models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic of Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Introduction to Tensorflow   \n",
    "- [**TensorFlow**](https://www.tensorflow.org) is a software library, developed by Google Brain Team within Google's Machine Learning Intelligence research organization, for the purposes of conducting machine learning and deep neural network research.\n",
    "- TensorFlow combines the computational algebra of compilation optimization techniques, making easy the calculation of many mathematical expressions that would be difficult to calculate, instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main features\n",
    "* Defining, optimizing, and efficiently calculating mathematical expressions involving multi-dimensional arrays (tensors).\n",
    "* Programming support of **deep neural networks** and machine learning techniques.\n",
    "* Transparent use of GPU computing, automating management and optimization of the same memory and the data used. You can write the same code and run it either on CPUs or GPUs. More specifically, TensorFlow will figure out which parts of the computation should be moved to the GPU.\n",
    "* High scalability of computation across machines and huge data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Tensors and operations based on eager execution\n",
    "\n",
    "TensorFlow is called TensorFlow because it handles the flow (node/mathematical operation) of Tensors (data), which you can think of as multidimensional arrays. In TensorFlow, computations can be thought of as graphs. In the previous version (<1.14) of Tensorflow, we implemented a computation graph thought a session we defined and ran the graphs in the session. But, the latest version does not use the session, it can be used simply through an eager executation.\n",
    "\n",
    "[**Eager execution**](https://www.tensorflow.org/guide/eager) is an imperative programming environment that evaluates operations immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later. This makes it easy to get started with TensorFlow and debug models, and it reduces boilerplate as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow:  2.0.0-rc0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Install TensorFlow\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "print('Tensorflow: ', tf.__version__)\n",
    "\n",
    "import cProfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Tensorflow 2.0, eager execution is enabled by default.\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define simple computation graph under the eager execution:\n",
    "\n",
    "![Computation Graph - Add Operation](https://i.imgur.com/K34aWFr.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Using the eager execution, create the nodes in the graph, then check the output\n",
    "a = \n",
    "b = \n",
    "c = \n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we've created a computation graph consisting of TensorFlow operations, and how the output is a Tensor with value 76 -- we've just created a computation graph consisting of operations, and it's executed them and given us back the result. That's because of Eager!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not eager execution (FYI)\n",
    "```python\n",
    "a = tf.constant(1, name='a')\n",
    "b = tf.constant(2, name='b')\n",
    "c = tf.add(a, b, name='c')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(c))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor\n",
    "\n",
    "A **tensor** is a generalization of vectors and matrices to potentially higher dimensions. Internally, TensorFlow represents tensors as n-dimensional arrays of base datatypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-D Tensor (Vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "pprint = partial(print, end='\\n\\n')\n",
    "\n",
    "tensor_1d = tf.constant([1, 2.5, 4.6, 5.75, 9.7], dtype=tf.float64, name='tensor_1d')\n",
    "print('tensor_1d =', tensor_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-D Tensor (Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_2d = tf.constant(np.arange(16).reshape(4, 4), dtype=tf.float64, name='tensor_2d')\n",
    "print('tensor_2d =', tensor_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic operations in Tensorflow\n",
    "You can run TensorFlow operations and the results will return immediately because of eager execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.constant([\n",
    "    [4, 3],\n",
    "    [1, 1],\n",
    "], dtype=tf.float32, name='A')\n",
    "\n",
    "B = tf.constant([\n",
    "    [3, 5],\n",
    "    [1, 2],\n",
    "], dtype=tf.float32, name='B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.reduce_sum`: Computes the sum of elements across dimensions of a tensor. (deprecated arguments) <br>\n",
    "`tf.matrix_determinant`: Computes the determinant of one or more square matrices. <br>\n",
    "    (e.g. if given matrix is [[a, b], [c, d]], the output of this matrix is ad-bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint('A + B =', )\n",
    "pprint('A - B =', )\n",
    "pprint('A ⨉ B =', )\n",
    "pprint('A² =', )\n",
    "pprint('sum(A) =', )\n",
    "pprint('inv(A) =', )\n",
    "pprint('A ⨉ inv(A) =', )\n",
    "print('det(A) =', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as urllib2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a file-like object from the url\n",
    "f = urllib2.urlopen(\"http://matplotlib.sourceforge.net/_static/logo2.png\")\n",
    "\n",
    "# read the image file in a numpy array\n",
    "image = plt.imread(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.slice(input_,begin,size,name=None)`: Extract a slice of _size_ from a tensor input starting at the location specified by _begin_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Slice the tensor')\n",
    "sliced = tf.slice(image, [50, 0, 0], [50, -1, -1]) # imput, begin, size\n",
    "plt.imshow(sliced)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.transpose(a,perm=None,name='transpose',conjugate=False)`: Transposes _a_. Permutes the dimensions according to _perm_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Transepose the tensor')\n",
    "transposed = tf.transpose(image, perm=[1, 0, 2])\n",
    "plt.imshow(transposed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic control flow\n",
    "\n",
    "As you've seen, TensorFlow now supports an imperative programming style, and that's all because of Eager. As another example of the power of Eager, let's take a look at how we can build a dynamic model that uses Python flow control. Here's an example of the [Fizz buzz](https://en.wikipedia.org/wiki/Fizz_buzz) using TensorFlow’s arithmetic operations. Such dynamic behavior is not possible in past versions of TensorFlow (up to v1.4)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fizzbuzz(max_num):\n",
    "    counter = tf.constant(0)\n",
    "    max_num = tf.convert_to_tensor(max_num)\n",
    "    \n",
    "    for num in range(1, max_num.numpy() + 1):\n",
    "        num = tf.constant(num)\n",
    "        if int(num % 3) == 0 and int(num % 5) == 0:\n",
    "            print('FizzBuzz')\n",
    "        elif int(num % 3) == 0:\n",
    "            print('Fizz')\n",
    "        elif int(num % 5) == 0:\n",
    "            print('Buzz')\n",
    "        else:\n",
    "            print(num.numpy())\n",
    "            \n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fizzbuzz(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has conditionals that depend on tensor values and it prints these values at runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Neural networks in TensorFlow\n",
    "\n",
    "We can define neural networks in TensorFlow, and it's often helpful to think about this using the idea of computation graphs. TensorFlow uses a high-level API called [Keras](https://www.tensorflow.org/guide/keras) that provides a powerful, intuitive framework for building and training deep learning models. In this lecture, we'll be using the Keras API to build and train our models.\n",
    "\n",
    "Let's consider this example of a very simple neural network of just one dense layer:\n",
    "\n",
    "<img src=\"https://i.imgur.com/NxfQgpy.png\" width=\"600\">\n",
    "\n",
    "This graph takes an input `x` and computes an output `out = sigmoid(W * x + b)`. \n",
    "\n",
    "First, let's define this computation graph in TensorFlow via a simple function, as we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_in: number of inputs\n",
    "# n_out: number of outputs\n",
    "def our_dense_layer(x, n_in, n_out):\n",
    "    # TODO: define and initialize parameters, a weight matrix W and biases b\n",
    "    #       x.shape = (..., n_in)\n",
    "    #       W.shape = (n_in, n_out)\n",
    "    #       b.shape = (1, n_out)\n",
    "    W =\n",
    "    b = \n",
    "    \n",
    "    # TODO: define the operation for z (hint: use tf.matmul)\n",
    "    z = \n",
    "\n",
    "    # TODO: define the operation for out (hint: use tf.sigmoid)\n",
    "    out = \n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can define an example input, feed it into `our_dense_layer` function, and immediately execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an example input (x_input)\n",
    "x_input = tf.constant([[1.0, 2.0]])\n",
    "\n",
    "# TODO: call `our_dense_layer` to get the output of the network\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow with Keras\n",
    "Now, instead of explicitly defining a simple function, we'll use the Keras API to define our neural network. This will be especially important as we move on to more complicated network architectures.\n",
    "\n",
    "Specifically, for this network we'll use the Keras Sequential model from the tf.keras API to define our network. The tf.keras.Sequential model lets us conveniently define a linear stack of network layers. We'll use tf.keras.layers.Dense to define our single fully connected network layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of inputs and outputs\n",
    "n_input_nodes = 2\n",
    "n_output_nodes = 3\n",
    "\n",
    "# TODO: define a sequential model using Keras API\n",
    "model = \n",
    "# TODO: define a dense (fully connected) layer to compute z using Keras API \n",
    "dense_layer = \n",
    "# TODO: add the dense layer to the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an example input (x_input)\n",
    "x_input = tf.constant([[1.0, 2.0]])\n",
    "\n",
    "# TODO: feed the input into `model` and get the output\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Tensorflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a typical system, there are multiple computing devices. \n",
    "\n",
    "In TensorFlow, the supported device types are **CPU** and **GPU**. \n",
    "\n",
    "They are represented as strings. For example:\n",
    "\n",
    "* `'/cpu:0'`: The CPU of your machine.\n",
    "* `'/gpu:0'`: The GPU of your machine, if you have one.\n",
    "* `'/gpu:1'`: The second GPU of your machine, etc.\n",
    "    \n",
    "If a TensorFlow operation has both **CPU** and **GPU** implementations, the GPU devices will be given priority when the operation is assigned to a device. \n",
    "\n",
    "For example, `matmul` has both CPU and GPU kernels. On a system with devices `cpu:0` and `gpu:0`, `gpu:0` will be selected to run `matmul`.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "available_gpus = get_available_gpus()\n",
    "print(available_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "if tf.test.is_gpu_available():\n",
    "    for d in available_gpus:\n",
    "        with tf.device(d):\n",
    "            a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])\n",
    "            b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])\n",
    "            c.append(tf.matmul(a, b))\n",
    "            \n",
    "    with tf.device('/cpu:0'):\n",
    "        result = tf.add_n(c)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    a = tf.random.normal((512, 64, 32, 32))\n",
    "    b = tf.random.normal((512, 64, 32, 32))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    tf.matmul(a, b)\n",
    "    end_time = time.time()\n",
    "\n",
    "print('Elapsed time: {:.4f}s'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    a = tf.random.normal((512, 64, 32, 32))\n",
    "    b = tf.random.normal((512, 64, 32, 32))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    tf.matmul(a, b)\n",
    "    end_time = time.time()\n",
    "    \n",
    "print('Elapsed time: {:.4f}s'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More on Tensorflow\n",
    "\n",
    "[Official API Documentation](https://www.tensorflow.org/api_docs/python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "gdrive_root = '/gdrive/My Drive'\n",
    "print('In gdrive :', os.listdir(gdrive_root))\n",
    "\n",
    "notebook_dir = os.path.join(gdrive_root, 'Colab Notebooks')\n",
    "print('In Colab Notebooks :', os.listdir(notebook_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "!wget https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTtmYIYGx1zXVT4UyjturF3uL7AWx4FKdfJJAnjCrPKxJnjHSxJ -O '/gdrive/My Drive/strawberry.png'\n",
    "print('In gdrive :', os.listdir(gdrive_root))\n",
    "\n",
    "image_path = os.path.join(gdrive_root, 'strawberry.png')\n",
    "img = Image.open(image_path)\n",
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
