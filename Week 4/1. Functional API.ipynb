{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS492 전산학특강<인공지능 산업 및 스마트에너지>\n",
    "## Deep Learning Practice \n",
    "#### Prof. Ho-Jin Choi\n",
    "#### School of Computing, KAIST\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 - Cumstomization \n",
    "## Schedule of this week\n",
    "7. **Customization of your model**  <br>\n",
    "    7-1. Functional API  <br>\n",
    "    7-2. Cumstomization of loss and metric <br>\n",
    "    7-3. Several options for optimizer and training <br>\n",
    "    7-4. Subclassing and GradientTape <br>\n",
    "    7-5. Custom layers and training <br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Customization of your models\n",
    "### 7-1. Functional API in Tensorflow \n",
    "#### (Customization of sequence of forward passing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a model using functional API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're already familiar with the use of `keras.Sequential()` to create models. The _Functional API_ is **a way to create models that is more flexible than _Sequential_: it can handle models with non-linear topology, models with shared layers, and models with multiple inputs or outputs.**\n",
    "\n",
    "It's based on the idea that a deep learning model is usually a directed acyclic graph (DAG) of layers. The Functional API a set of tools for building graphs of layers.\n",
    "\n",
    "Consider the following model:\n",
    "``` python\n",
    "(input: 784-dimensional vectors)\n",
    "       ↧\n",
    "[Dense (64 units, relu activation)]\n",
    "       ↧\n",
    "[Dense (10 units, softmax activation)]\n",
    "       ↧\n",
    "(output: probability distribution over 10 classes)\n",
    "```\n",
    "\n",
    "It's a simple graph of 3 layers.\n",
    "\n",
    "To build this model with the functional API, you would start by creating an _input node_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# Build an input node\n",
    "inputs = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the input shape is a (32, 32, 3) image, we can build the input node as follows: \n",
    "``` python \n",
    "img_inputs = keras.Input(shape=(32, 32, 3))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just specify the shape of our data: 784-dimensional vectors. Note that the batch size is always omitted, **we only specify the shape of each sample.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You create a new node in the graph of layers by calling a layer on this inputs object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# define a new dense layer\n",
    "dense = \n",
    "\n",
    "# build the dense layer to the graph of layers\n",
    "# by feeding outputs of input layer to the dense layer as an input \n",
    "# ==> Layer call \n",
    "x ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _\"layer call\"_ action is like drawing an arrow from \"inputs\" to this layer we created. We're \"passing\" the inputs to the dense layer, and out we get x.\n",
    "\n",
    "Let's add a few more layers to our graph of layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build more layers \n",
    "x =\n",
    "outputs ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can create a Model by specifying its inputs and outputs in the graph of layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "# create a model \n",
    "model ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, here is our full model definition process:\n",
    "\n",
    "``` python\n",
    "inputs = keras.Input(shape=(784,), name='img')\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out what the model summary looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the model as a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, 'my_first_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure and the code we wrote are virtually identical. In the code version, the connection arrows are simply replaced by the call operation.\n",
    "\n",
    "A \"graph of layers\" is a very intuitive mental image for a deep learning model, and the functional API is a way to create models that closely mirrors this mental image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training, evaluation, and inference\n",
    "\n",
    "Training, evaluation, and inference work exactly in the same way for models built using the Functional API as for Sequential models.\n",
    "\n",
    "To simply demonstrate our model, we load MNIST image data, reshape it into vectors, fit the model on the data (while monitoring performance on a validation split), and finally we evaluate our model on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=5,\n",
    "                    validation_split=0.2)\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the same graph of layers to define multiple models\n",
    "In the functional API, models are created by specifying their inputs and outputs in a graph of layers. **That means that a single graph of layers can be used to generate multiple models.**\n",
    "\n",
    "**Simple autoencoder example:** <br>\n",
    "In the example below, we use the same stack of layers to instantiate two models: an `encoder` model that turns image inputs into 16-dimensional vectors, and an end-to-end `autoencoder` model for training.\n",
    "<img src=https://lilianweng.github.io/lil-log/assets/images/autoencoder-architecture.png>\n",
    "\n",
    "[`tf.keras.layers.Conv2DTranspose`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose): Transposed convolution layer (sometimes called Deconvolution). <br>\n",
    "[`tf.keras.layers.UpSampling2D\n",
    "`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D): Upsampling layer for 2D inputs. (`size`: The upsampling factors for rows and columns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
    "# (28x28x1) -> Conv2D layer with filters(Channel) 16, kernel_size 3, relu activation\n",
    "x = \n",
    "# (26x26x16) -> Conv2D layer with filters(Channel) 32, kernel_size 3, relu activation\n",
    "x = \n",
    "# (24x24x32) -> MaxPooling2D layer with pooling size 3\n",
    "x = \n",
    "# (8x8x32) -> Conv2D layer with filters(Channel) 32, kernel_size 3, relu activation\n",
    "x = \n",
    "# (6x6x32) -> Conv2D layer with filters(Channel) 32, kernel_size 3, relu activation\n",
    "x =\n",
    "# (4x4x16) -> GlobalMaxPooling2D\n",
    "encoder_output =\n",
    "# (16,)\n",
    "\n",
    "encoder = \n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(encoder, 'encoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the output of encoder model as an input of autoencoder model\n",
    "x = \n",
    "x = \n",
    "x = \n",
    "x = \n",
    "x = \n",
    "decoder_output = \n",
    "\n",
    "# define the model using encoder_input and decoder_output\n",
    "autoencoder =\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(autoencoder, 'autoencoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All models are callable, just like layers\n",
    "You can treat any model as if it were a layer, by calling it on an Input or on the output of another layer. Note that by calling a model you aren't just reusing the architecture of the model, **you're also reusing its weights.**\n",
    "\n",
    "Let's see this in action. Here's a different take on the autoencoder example that creates an encoder model, a decoder model, and chain them in two calls to obtain the autoencoder model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name='original_img')\n",
    "x = layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(16, 3, activation='relu')(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = keras.Input(shape=(16,), name='encoded_img')\n",
    "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation='relu')(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation='relu')(x)\n",
    "\n",
    "decoder = keras.Model(decoder_input, decoder_output, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_input = \n",
    "encoded_img = \n",
    "decoded_img = \n",
    "autoencoder = \n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, **model can be nested: a model can contain submodels (since a model is just like a layer).**\n",
    "\n",
    "**A common use case for model nesting is _ensembling_.** As an example, here's how to ensemble a set of models into a single model that averages their predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(128,))\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(inputs)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "model1 = \n",
    "model2 = \n",
    "model3 =\n",
    "\n",
    "inputs = \n",
    "y1 =\n",
    "y2 = \n",
    "y3 = \n",
    "outputs =\n",
    "ensemble_model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of ensembling method:**\n",
    "1. Reducing an overfitting by combining several models.\n",
    "1. Improving the overall performance when each model performance is low\n",
    "\n",
    "For more detailed explanation about ensembliig method, refer to this site: https://en.wikipedia.org/wiki/Ensemble_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulating complex graph topologies\n",
    "The **functional API makes it easy to manipulate multiple inputs and outputs**. This cannot be handled with the Sequential API.\n",
    "\n",
    "Here's a simple example.\n",
    "\n",
    "Let's say you're building a system for ranking custom issue tickets by priority and routing them to the right department.\n",
    "\n",
    "You model will have 3 inputs:\n",
    "- Title of the ticket (text input)\n",
    "- Text body of the ticket (text input)\n",
    "- Any tags added by the user (categorical input)\n",
    "\n",
    "It will have two outputs:\n",
    "- Priority score between 0 and 1 (scalar sigmoid output)\n",
    "- The department that should handle the ticket (softmax output over the set of departments)\n",
    "\n",
    "Let's built this model in a few lines with the Functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = 12  # Number of unique issue tags\n",
    "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
    "num_departments = 4  # Number of departments for predictions\n",
    "\n",
    "title_input = keras.Input(shape=(None,), name='title')  # Variable-length sequence of ints\n",
    "body_input = keras.Input(shape=(None,), name='body')  # Variable-length sequence of ints\n",
    "tags_input = keras.Input(shape=(num_tags,), name='tags')  # Binary vectors of size `num_tags`\n",
    "\n",
    "# Embed each word in the title into a 64-dimensional vector\n",
    "title_features = \n",
    "# Embed each word in the text into a 64-dimensional vector\n",
    "body_features = \n",
    "# input shape of embeeding layer: (batch_size, input_length)\n",
    "# output shape of embedding layer: (batch_size, input_length, embedding_dim)\n",
    "\n",
    "# Reduce sequence of embedded words in the title into \n",
    "# a single 128-dimensional vector\n",
    "title_features = \n",
    "# Reduce sequence of embedded words in the body into \n",
    "# a single 32-dimensional vector\n",
    "body_features = \n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = \n",
    "\n",
    "# Stick a logistic regression for priority prediction on top of the features\n",
    "priority_pred = \n",
    "# Stick a department classifier on top of the features\n",
    "department_pred =\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When compiling this model, we can **assign different losses to each output.** You can even **assign different weights to each loss**, to modulate their contribution to the total training loss. (e.g., Be able to adjust weight of important loss to affect learning more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the loss using the names of output layers\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "              loss={'priority': 'binary_crossentropy',\n",
    "                    'department': 'categorical_crossentropy'},\n",
    "              loss_weights=[1., 0.2])\n",
    "\n",
    "\"\"\"\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "              loss=['binary_crossentropy', 'categorical_crossentropy'],\n",
    "              loss_weights=[1., 0.2])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train the model by passing lists of Numpy arrays of inputs and targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dummy input data\n",
    "title_data = np.random.randint(num_words, size=(1280, 10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tags_data = np.random.randint(2, size=(1280, num_tags)).astype('float32')\n",
    "\n",
    "print(title_data.shape)\n",
    "print(body_data.shape)\n",
    "print(tags_data.shape)\n",
    "print(\"-------------------\\n\")\n",
    "\n",
    "print(title_data[0])\n",
    "print(body_data[0])\n",
    "print(tags_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy target data\n",
    "priority_targets = np.random.random(size=(1280, 1))\n",
    "dept_targets = np.random.randint(2, size=(1280, num_departments))\n",
    "\n",
    "print(priority_targets[0])\n",
    "print(dept_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit({'title': title_data, 'body': body_data, 'tags': tags_data}, # set training data\n",
    "          {'priority': priority_targets, 'department': dept_targets},  # set target data (labels)\n",
    "          epochs=2,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calling fit with a `Dataset` object, it should yield either a tuple of lists like `([title_data, body_data, tags_data], [priority_targets, dept_targets])` or a tuple of dictionaries like `({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A toy resnet model\n",
    "In addition to models with multiple inputs and outputs, **the Functional API makes it easy to manipulate non-linear connectivity topologies**, that is to say, models where layers are not connected sequentially. This also cannot be handled with the Sequential API (as the name indicates).\n",
    "\n",
    "A common use case for this is **residual connections**.\n",
    "\n",
    "<img src=https://miro.medium.com/proxy/1*rbhjv7ZdAgXM2MlBUL5Mmw.png>\n",
    "\n",
    "\n",
    "Let's build a toy ResNet model for CIFAR10 to demonstrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3), name='img')\n",
    "\n",
    "## Normal connection\n",
    "# Conv2D with filters 32, kernel_size 3, relu activation\n",
    "x = \n",
    "# Conv2D with filters 64, kernel_size 3, relu activation\n",
    "x = \n",
    "block_1_output =\n",
    "\n",
    "# Conv2D with filters 64, kernel_size 3, relu activation, padding 'same' (with zero padding)\n",
    "x = \n",
    "# Conv2D with filters 64, kernel_size 3, relu activation, padding 'same' (with zero padding)\n",
    "x = \n",
    "# Use the block_1_output and x as an input\n",
    "block_2_output = \n",
    "\n",
    "# Conv2D with filters 64, kernel_size 3, relu activation, padding 'same' (with zero padding)\n",
    "x = \n",
    "# Conv2D with filters 64, kernel_size 3, relu activation, padding 'same' (with zero padding)\n",
    "x = \n",
    "# Use the block_2_output and x as an input\n",
    "block_3_output = \n",
    "\n",
    "# Conv2D with filters 64, kernel_size 3, relu activation\n",
    "x = \n",
    "# GlobalAveragePooling2D\n",
    "x = \n",
    "# Dense layer with 256 units\n",
    "x =\n",
    "# Dropout layer with 0.5 dropout rate\n",
    "x = \n",
    "# Dense layer with 10 units, softmax function\n",
    "outputs = \n",
    "\n",
    "\n",
    "model = \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, 'mini_resnet.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=1,\n",
    "          validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
